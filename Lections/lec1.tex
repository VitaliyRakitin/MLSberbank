\documentclass[a4paper,14pt]{article}
\input{AESh.sty}
\usepackage{caption}
\usepackage{pdfpages}
    
    
\begin{document}
\section{Леция 1.  }
\subsection {Введение.}
Где применяется машинное обучение:
\begin{itemize}
    \item Цены на нефть (есть данные нужно предсказать дальнейшее развитие);
    \item Кредитный скоринг (есть человек, есть кредит --- надо понять давать ему кредит или нет. Предсказываем вероятность того, на сколько он хороший заёмщик);
    \item Предсказание температуры (диапазон значений);
    \item Таргетированная реклама (на основе предпочтений подбираем наиболее подходящие товары);
    \item Информационный поиск;
    \item Персонализация (наиболее интересные новости VK -- градиентный бустинг деревьев);
    \item Чат-боты (NN);
    \item Призма;
    \item Генерация изображений (GAN); \link{https://deepmind.com/blog}
    \item Боты в играх (reinforcement learning);
\end{itemize}

{\it Замечание:} Анонсирован градиентный бустинг на 2 занятии.

{\it Замечание:} Мода на сеточки :D надо доказать людям, что заниматься не нейронками тоже прикольно.


\subsection{По сути}

Пусь у нас есть тренировачные данные кредитного скоринга:
\begin{itemize}
    \item Пол;
    \item Возраст;
    \item Возвращают кредит или нет;
\end{itemize} 

Хотим предсказать вернёт он нам кредит или нет.

{\it Определение.} Дано $X$ --- обучающая выборка (множество объектов), где $x \in X = \{x\}$ --- прецедент, модель ML, после чего {\bf модель} обучается --- получается алгоритм машинного обучения. Y -- множество допустимых ответов (target).

Данные необходимо проверять --- модель хочет понять на сколько хорошо модель <<понимает>> данные, которые она никогда не видела. Проверяем обобщающую способность данных.

{\it Определение.} $y^{*}: X \rightarrow Y$ --- {\bf целевая функция.} Имеем значения только на конечном наборе данных $x_i \in X:$ $y^{*}(x_i) = y_i$. Сопоставляем входным данным соответствующие ответы.

{\it Определение.} $a$ --- {\bf решающая функция (алгоритм)} --- обобщение функции $y^{*}$ на всё множество объектов.

\[
    X = X_{\mathrm{train}} \cup X_{\mathrm{test}}
\]

Делим выборку на обучающую + тестовую.

{\it Замечание} {\bf Kaggle.} Титаник.

{\it Определение.} {\bf Признак } (feature) объекта x --- это результа измерения характеристики объекта. Для $x_j = \{x_j^{1}, \dots, x_j^{n}\}$ --- признаковое описание объекта (вектор).

Можно генерировать новые признаки различными алгоритмами (feature engineering).

Очень круто выяснить какие features наиболее важны для модели.

{\bf Формализуем:} по выборке $X_{\mathrm{train}}$ построить решающую функцию которая хорошо приблежает $y^{*}$ как на $X_{train}$, так и на всём множестве $X$.

Чтобы решать задачу необходимо ввести функционал качества. Для этого необходимо ввести метрику и функцию ошибки. Решаем задачу оптимизации: ищем набор параметров в пространстве параметров такой, чтобы Максимизировать функционал качества, минимизировать функцию ошибок ($Loss$).

\subsection{Метрики качества }
\[
    MAE = \frac{1}{N} \sum\limits_{1}^{N} | y_i - y_i^{*}|
\]

\[ 
    MSE = \frac{1}{N} \sum\limits_{1}^{N}  (y_i - y_i^{*})^2
\]
\[
    accuracy = \frac{TP + TN}{TP + TN + FP + FN}    
\]
\[
    PRE = \frac{TP }{TP + FP}    
\] 
\[
    REC = \frac{TP}{TP + FN}    
\]
\[
    F = 2 \cdot \frac{PRE \cdot REC}{PRE+REC}
\]

\begin{itemize}
    \item TP --- 1 и алгоритм говорит, что 1;
    \item TN --- 0 и алгоритм говорит, что 0;
    \item FP --- 0 алгоритм говорит, что 1;
    \item FN --- 1 алгоритм говорит, что 0;
\end{itemize}
Для оценки качества работы алгоритма на каждом из классов по отдельности введем метрики precision (точность) и recall (полнота).

Precision можно интерпретировать как долю объектов, названных классификатором положительными и при этом действительно являющимися положительными, а recall показывает, какую долю объектов положительного класса из всех объектов положительного класса нашел алгоритм.

Почему нужны эти метрики: Если данных одного класса сильно больше, чем другого, то алгоритму проще обучиться всегда выводить первый класс (вероятность ошибки ниже при accuracy). А precision и recall смещают данные.

\section{Машинное обучение}
\begin{itemize}
    \item Классическое обучение (с учителем -- без);
    \item Ансамблевые методы (много моделек);
\end{itemize}

{\it Определение.}  Классификация. есть множество объектов и множество классов (конечное). Обучаем модель, разделяющую данные на группы.

{\it Определение.}  Регрессия. отличается тем, что допустимым ответом является число или числовой вектор (пространство непрерывно, бескоечное множество ответов).

Без учителя:
\begin{itemize}
    \item Кластеризация;
    \item Поиск правил;
    \item Уменьшение размерности;
\end{itemize}


{\it Определение.} {\bf Переобучение } --- модель находит зависимости там, где их нет (например у всех плохих заёмщиков были крассные ботинки);
Причины:
\begin{itemize}
    \item Слишком много степеней свободы (слишком большая модель);
    \item Мало данных (general зависимости не находим, а находим локальные зависимости);
\end{itemize}

{\it Определение.} Валидационная выборка --- знаем на ней ответы (на тестовой не знаем);

{\it Определение.} Кросс-валидация --- ошибка на валидационных данных не отображает реальной картины мира.
Делим N раз на валидационную и тестовую, N раз тренируем алгоритм, считаем среднюю ошибку.

{\bf Методы борьбы}

{\it Регуляризация} (добавляем функцию от весов в loss, сдерживаем их рост)
\end{document}