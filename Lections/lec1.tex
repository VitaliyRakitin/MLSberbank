\documentclass[a4paper,14pt]{article}
\input{AESh.sty}
\usepackage{caption}
\usepackage{pdfpages}
    
    
\begin{document}
    \tableofcontents

\newpage
\section{Леция 1.}
\subsection {Введение.}
Где применяется машинное обучение:
\begin{itemize}
    \item Цены на нефть (есть данные нужно предсказать дальнейшее развитие);
    \item Кредитный скоринг (есть человек, есть кредит --- надо понять давать ему кредит или нет. Предсказываем вероятность того, на сколько он хороший заёмщик);
    \item Предсказание температуры (диапазон значений);
    \item Таргетированная реклама (на основе предпочтений подбираем наиболее подходящие товары);
    \item Информационный поиск;
    \item Персонализация (наиболее интересные новости VK -- градиентный бустинг деревьев);
    \item Чат-боты (NN);
    \item Призма;
    \item Генерация изображений (GAN); \hyperlink{https://deepmind.com/blog}{https://deepmind.com/blog}
    \item Боты в играх (reinforcement learning);
\end{itemize}

{\it Замечание:} Анонсирован градиентный бустинг на 2-ом занятии.

{\it Замечание:} Мода на сеточки :D надо доказать людям, что заниматься не нейронками тоже прикольно.


\subsection{По сути}

Пусь у нас есть тренировачные данные кредитного скоринга:
\begin{itemize}
    \item Пол;
    \item Возраст;
    \item Возвращают кредит или нет;
\end{itemize} 

Хотим предсказать вернёт он нам кредит или нет.

{\it Определение.} Дано $X$ --- обучающая выборка (множество объектов), где $x \in X = \{x\}$ --- прецедент, модель ML, после чего {\bf модель} обучается --- получается алгоритм машинного обучения. Y -- множество допустимых ответов (target).

Данные необходимо проверять --- модель хочет понять на сколько хорошо модель <<понимает>> данные, которые она никогда не видела. Проверяем обобщающую способность данных.

{\it Определение.} $y^{*}: X \rightarrow Y$ --- {\bf целевая функция.} Имеем значения только на конечном наборе данных $x_i \in X:$ $y^{*}(x_i) = y_i$. Сопоставляем входным данным соответствующие ответы.

{\it Определение.} $a$ --- {\bf решающая функция (алгоритм)} --- обобщение функции $y^{*}$ на всё множество объектов.

\[
    X = X_{\mathrm{train}} \cup X_{\mathrm{test}}
\]

Делим выборку на обучающую + тестовую.

{\it Замечание} {\bf Kaggle.} Титаник.

{\it Определение.} {\bf Признак } (feature) объекта x --- это результа измерения характеристики объекта. Для $x_j = \{x_j^{1}, \dots, x_j^{n}\}$ --- признаковое описание объекта (вектор).

Можно генерировать новые признаки различными алгоритмами (feature engineering).

Очень круто выяснить какие features наиболее важны для модели.

{\bf Формализуем:} по выборке $X_{\mathrm{train}}$ построить решающую функцию которая хорошо приблежает $y^{*}$ как на $X_{train}$, так и на всём множестве $X$.

Чтобы решать задачу необходимо ввести функционал качества. Для этого необходимо ввести метрику и функцию ошибки. Решаем задачу оптимизации: ищем набор параметров в пространстве параметров такой, чтобы Максимизировать функционал качества, минимизировать функцию ошибок ($Loss$).

\subsection{Метрики качества }
\[
    MAE = \frac{1}{N} \sum\limits_{1}^{N} | y_i - y_i^{*}|
\]

\[ 
    MSE = \frac{1}{N} \sum\limits_{1}^{N}  (y_i - y_i^{*})^2
\]
\[
    accuracy = \frac{TP + TN}{TP + TN + FP + FN}    
\]
\[
    PRE = \frac{TP }{TP + FP}    
\] 
\[
    REC = \frac{TP}{TP + FN}    
\]
\[
    F = 2 \cdot \frac{PRE \cdot REC}{PRE+REC}
\]

\begin{itemize}
    \item TP --- 1 и алгоритм говорит, что 1;
    \item TN --- 0 и алгоритм говорит, что 0;
    \item FP --- 0 алгоритм говорит, что 1;
    \item FN --- 1 алгоритм говорит, что 0;
\end{itemize}
Для оценки качества работы алгоритма на каждом из классов по отдельности введем метрики precision (точность) и recall (полнота).

Precision можно интерпретировать как долю объектов, названных классификатором положительными и при этом действительно являющимися положительными, а recall показывает, какую долю объектов положительного класса из всех объектов положительного класса нашел алгоритм.

Почему нужны эти метрики: Если данных одного класса сильно больше, чем другого, то алгоритму проще обучиться всегда выводить первый класс (вероятность ошибки ниже при accuracy). А precision и recall смещают данные.

\section{Машинное обучение}
\begin{itemize}
    \item Классическое обучение (с учителем -- без);
    \item Ансамблевые методы (много моделек);
\end{itemize}

{\it Определение.}  Классификация. есть множество объектов и множество классов (конечное). Обучаем модель, разделяющую данные на группы.

{\it Определение.}  Регрессия. отличается тем, что допустимым ответом является число или числовой вектор (пространство непрерывно, бескоечное множество ответов).

Без учителя:
\begin{itemize}
    \item Кластеризация;
    \item Поиск правил;
    \item Уменьшение размерности;
\end{itemize}


{\it Определение.} {\bf Переобучение } --- модель находит зависимости там, где их нет (например у всех плохих заёмщиков были красные ботинки);
Причины:
\begin{itemize}
    \item Слишком много степеней свободы (слишком большая модель);
    \item Мало данных (general зависимости не находим, а находим локальные зависимости);
\end{itemize}

{\it Определение.} Валидационная выборка --- знаем на ней ответы (на тестовой не знаем);

{\it Определение.} Кросс-валидация --- ошибка на валидационных данных не отображает реальной картины мира.
Делим N раз на валидационную и тестовую, N раз тренируем алгоритм, считаем среднюю ошибку.

{\bf Методы борьбы}

{\it Регуляризация} (добавляем функцию от весов в loss, сдерживаем их рост)

\newpage
\section{ Лекция 2. Модели, ансамбли моделей }
    \subsection{Зоопарк моделей}
    Занимаемся моделями обучения с учителем.

    Есть 2 варианта постановки задачи:
    \begin{itemize}
        \item Классификация;
        \item Регрессия;
    \end{itemize}

    \subsubsection{Наивный байесовский классификатор}
    Самый простой способ, как построить себе модель.

    {\bf Замечание.} { \it Только классификация.}

    Для класса определяем вероятность. Есть условная вероятость, как часто встречается фича с фиксированной величиной для каждого класса.

    По формуле Байеса найдём вероятность ответа при значении фичей.
    \[
        p(A|B) = \frac{p(A) \cdot p(B|A) }{ p(B) }
    \]

    {\bf Определение.} { \it Априорная вероятность.} -- это вероятность, присвоенная событию при отсутствии знания, поддерживающего его наступление $p(A)$;

    {\bf Определение.} { \it Апостериорная вероятност.} -- это условная вероятность события $p(A|B)$.


    \begin{itemize}
        \item Spam detection;
        \item Сегментация новостных статей по теме;
        \item Определение эмоционального окраса текста;
    \end{itemize}

    \subsubsection{Линейные модели}

    {\bf Определение.} { \it Линейная модель.} выражается линейной функцией.
    \[
        Y_i = \beta_0 + \beta_1 f(X_{i1}) + \cdot + \beta_p f(X_{ip}) + \e_i
    \]
    Где $\e_i$ -- шум (гауссово распределение), $i = 1,\dots, N$.

    {\bf Замечание.} Функции $f_1, \dots, f_p$ не обязательно должны быть линейными.

    \subsubsection{Линейная регрессия}

    \[
        y = X \cdot w^{T} + \e
    \]

    В данном случае решение будет решением СЛАУ:
    \[
        w^T = \left(X^{T}X\right)^{-1}X^T y
    \]

    {\bf Проблема 1.} решение будет <<осмысленным>> только тогда, когда в данных реально есть линейная зависимость. В реальных данных почти не встречается.

    {\bf Проблема 2.} Линейная зависимость признаков, $\det X^{T}X$ должен быть отличен от $0$.

    Решение проблемы: {\bf регуляризация}:
    \[
        w^T = \left(X^{T}X + \lambda \cdot \mathrm{Id} \right)^{-1}X^T y
    \]

    \subsubsection{Градиентный спуск}

    Веса модели ищутся с помощью градиентного спуска
    \begin{enumerate}
        \item Инициализация $W$ случайными значениями;
        \item Итеративно для всех сэмплов $x \in X$:
        \begin{enumerate}
            \item Вычислить функцию потерь на $x$;
            \item Вычислить производные функции потерь $grad_w$ по каждому из $w \in W$;
            \item Обновляем веса: $w = w - \mathrm{lr} \cdot grad_w$
        \end{enumerate}
        \item Полученное $W = \{w\}$ --- искомое.
    \end{enumerate}

    Для линейной регрессии функция потерь:
    \[
        MSE = \frac{1}{N} \sum\limits_{i=1}^N \left( y_i - (W x_i + b)\right) ^ 2
    \]

    {\bf Пролемы:}
    \begin{itemize}
        \item Переобучение\\
        {\it Как бороться:} при переобучении коэффициенты стремятся к бесконечности. Лечится регуляризацией.
        \[
           \text{Lasso Regresstion (L1): } MSE = \frac{1}{N} \sum\limits_{i=1}^N \left( y_i - (W x_i + b)\right) ^ 2 + \lambda  \sum\limits_{i=1}^N \left|W_{i}\right|
        \]
        \[
            \text{Ridge Regresstion (L2): } MSE = \frac{1}{N} \sum\limits_{i=1}^N \left( y_i - (W x_i + b)\right) ^ 2 + \lambda  \sum\limits_{i=1}^N W_{i}^2
        \]

        Эта красота эквивалентна задаче оптимизации:
        \[
            \begin{cases}
                MSE = \frac{1}{N} \sum\limits_{i=1}^N \left( y_i - (W x_i + b)\right) ^ 2 \rightarrow 0 \\
                \lambda  \sum\limits_{i=1}^N \left|W_{i}\right| \le C (=\mathrm{const})
            \end{cases}
        \]
    \end{itemize}

    \subsubsection{SVM. Метод опорных векторов}
    {\bf Цель:} построить линейную модель, которая делит наши выборки наилучшим образом. (ищем оптимальную разделяющую поверхность, наиболее удалённую от всех точек выборки)

    {\bf Пример:} пусть 2 класса -1 и 1. Хотим разделить: $y \cdot Xw > c$.

    Решаем задачу оптимизацию:
    \[
        \begin{cases}
            \mathrm{loss} \rightarrow \min \\
            ||w|| < b
        \end{cases}
    \]

    {\bf Цитата: } {\it Люди придумали нейронки и про это все забыли.}

    \subsubsection{Логистическая регрессия}
    \[
        y = \sigma(WX), \qquad \sigma(x) = \frac{1}{1 + e^{-x}}
    \]

    Задача ставится следующим образом:
    \[
        y = \sign(WX - b)
    \]



\end{document}